{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all csv files that are in the dataset folder\n",
    "all_files = glob.glob(\"data/*.csv\")\n",
    "\n",
    "# concatenate all the dataframes in the list\n",
    "df = pd.concat([pd.read_csv(file, index_col=None, header=0) for file in all_files], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_id</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@aichaabid1244</td>\n",
       "      <td>2023-12-17T11:28:07Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Chouha Chouha Atfou Atfou</td>\n",
       "      <td>2E3NYSgdnCA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@animeworldamv5052</td>\n",
       "      <td>2023-09-17T16:55:38Z</td>\n",
       "      <td>0</td>\n",
       "      <td>ÙˆØ§Ù„Ù„Ù‡ ÙŠØ§Ø®Ø¯ ÙÙŠÙƒÙ… Ø§Ù„Ø­Ù‚ Ø£ Ø´ÙˆÙ ØªÙŠÙÙŠ Ø§Ù„Ù„ÙŠ ÙƒØªØ¬ÙŠØ¨Ùˆ Ù„ÙŠ...</td>\n",
       "      <td>2E3NYSgdnCA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user-vl7bi8cn4g</td>\n",
       "      <td>2023-09-09T22:35:46Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø§Ù…Ø±Ø§Ø¡Ø© Ù„ÙˆÙƒØ§Ù†Øª ÙÙŠ Ø§Ù„Ø¬Ø²Ø§Ø¡Ø±  Ø¹Ø¸Ù… Ø§Ù„Ù„Ù‡ Ø§Ø¬Ø±Ø§ÙƒÙ…</td>\n",
       "      <td>2E3NYSgdnCA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@wassifsiham3156</td>\n",
       "      <td>2023-08-30T10:34:17Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Ù‡Ø§Ø¯ÙŠ ÙˆØ­ÙƒÙ…ØªÙˆÙ‡Ø§  ÙˆØ§Ø®Ù†ÙˆØ´  Ø§Ø´ Ù†Ø¯ÙŠØ±Ùˆ  ÙÙŠÙ‡  Ù‡Ø§Ø¯ÙŠ Ø±Ø§Ù‡...</td>\n",
       "      <td>2E3NYSgdnCA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@FatihaOudrhiri-np2ll</td>\n",
       "      <td>2023-07-29T18:35:45Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Il faut fermer ce youtoub car c est honteux de...</td>\n",
       "      <td>2E3NYSgdnCA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author            updated_at  like_count  \\\n",
       "0         @aichaabid1244  2023-12-17T11:28:07Z           0   \n",
       "1     @animeworldamv5052  2023-09-17T16:55:38Z           0   \n",
       "2       @user-vl7bi8cn4g  2023-09-09T22:35:46Z           0   \n",
       "3       @wassifsiham3156  2023-08-30T10:34:17Z           0   \n",
       "4  @FatihaOudrhiri-np2ll  2023-07-29T18:35:45Z           0   \n",
       "\n",
       "                                                text     video_id  public  \n",
       "0                          Chouha Chouha Atfou Atfou  2E3NYSgdnCA    True  \n",
       "1  ÙˆØ§Ù„Ù„Ù‡ ÙŠØ§Ø®Ø¯ ÙÙŠÙƒÙ… Ø§Ù„Ø­Ù‚ Ø£ Ø´ÙˆÙ ØªÙŠÙÙŠ Ø§Ù„Ù„ÙŠ ÙƒØªØ¬ÙŠØ¨Ùˆ Ù„ÙŠ...  2E3NYSgdnCA    True  \n",
       "2          Ø§Ù…Ø±Ø§Ø¡Ø© Ù„ÙˆÙƒØ§Ù†Øª ÙÙŠ Ø§Ù„Ø¬Ø²Ø§Ø¡Ø±  Ø¹Ø¸Ù… Ø§Ù„Ù„Ù‡ Ø§Ø¬Ø±Ø§ÙƒÙ…  2E3NYSgdnCA    True  \n",
       "3  Ù‡Ø§Ø¯ÙŠ ÙˆØ­ÙƒÙ…ØªÙˆÙ‡Ø§  ÙˆØ§Ø®Ù†ÙˆØ´  Ø§Ø´ Ù†Ø¯ÙŠØ±Ùˆ  ÙÙŠÙ‡  Ù‡Ø§Ø¯ÙŠ Ø±Ø§Ù‡...  2E3NYSgdnCA    True  \n",
       "4  Il faut fermer ce youtoub car c est honteux de...  2E3NYSgdnCA    True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Dataframe that containes only the columns and label \n",
    "new_df = df[[\"text\"]].dropna()\n",
    "new_df[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÙˆØ§Ù„Ù„Ù‡ ÙŠØ§Ø®Ø¯ ÙÙŠÙƒÙ… Ø§Ù„Ø­Ù‚ Ø£ Ø´ÙˆÙ ØªÙŠÙÙŠ Ø§Ù„Ù„ÙŠ ÙƒØªØ¬ÙŠØ¨Ùˆ Ù„ÙŠ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ø§Ù…Ø±Ø§Ø¡Ø© Ù„ÙˆÙƒØ§Ù†Øª ÙÙŠ Ø§Ù„Ø¬Ø²Ø§Ø¡Ø±  Ø¹Ø¸Ù… Ø§Ù„Ù„Ù‡ Ø§Ø¬Ø±Ø§ÙƒÙ…</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù‡Ø§Ø¯ÙŠ ÙˆØ­ÙƒÙ…ØªÙˆÙ‡Ø§  ÙˆØ§Ø®Ù†ÙˆØ´  Ø§Ø´ Ù†Ø¯ÙŠØ±Ùˆ  ÙÙŠÙ‡  Ù‡Ø§Ø¯ÙŠ Ø±Ø§Ù‡...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ÙˆØ§Ùƒ ÙˆØ§Ùƒ Ø§Ø¹Ø¨Ø§Ø¯ Ø§Ù„Ù„Ù‡ ÙˆØ§Ùƒ ÙˆØ§ÙƒğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ø³ÙŠÙ†ÙŠØ§Ù„ÙŠÙˆ Ø§Ù„Ù‚Ù†Ø§Ø© Ù„ÙŠ ÙƒØªØ´Ø¬Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø°ÙŠÙ„Ø© ÙˆØ§Ù„ÙØ³Ø§Ø¯</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "1  ÙˆØ§Ù„Ù„Ù‡ ÙŠØ§Ø®Ø¯ ÙÙŠÙƒÙ… Ø§Ù„Ø­Ù‚ Ø£ Ø´ÙˆÙ ØªÙŠÙÙŠ Ø§Ù„Ù„ÙŠ ÙƒØªØ¬ÙŠØ¨Ùˆ Ù„ÙŠ...      0\n",
       "2          Ø§Ù…Ø±Ø§Ø¡Ø© Ù„ÙˆÙƒØ§Ù†Øª ÙÙŠ Ø§Ù„Ø¬Ø²Ø§Ø¡Ø±  Ø¹Ø¸Ù… Ø§Ù„Ù„Ù‡ Ø§Ø¬Ø±Ø§ÙƒÙ…      0\n",
       "3  Ù‡Ø§Ø¯ÙŠ ÙˆØ­ÙƒÙ…ØªÙˆÙ‡Ø§  ÙˆØ§Ø®Ù†ÙˆØ´  Ø§Ø´ Ù†Ø¯ÙŠØ±Ùˆ  ÙÙŠÙ‡  Ù‡Ø§Ø¯ÙŠ Ø±Ø§Ù‡...      0\n",
       "5                     ÙˆØ§Ùƒ ÙˆØ§Ùƒ Ø§Ø¹Ø¨Ø§Ø¯ Ø§Ù„Ù„Ù‡ ÙˆØ§Ùƒ ÙˆØ§ÙƒğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚      0\n",
       "6       Ø³ÙŠÙ†ÙŠØ§Ù„ÙŠÙˆ Ø§Ù„Ù‚Ù†Ø§Ø© Ù„ÙŠ ÙƒØªØ´Ø¬Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø°ÙŠÙ„Ø© ÙˆØ§Ù„ÙØ³Ø§Ø¯      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the rows that have text in arabic\n",
    "new_df = new_df[new_df['text'].str.contains(u'[\\u0600-\\u06FF]')]\n",
    "\n",
    "# drop the rows that have more than 1 line of text\n",
    "new_df = new_df[~new_df['text'].str.contains('\\n')]\n",
    "\n",
    "# drop the rows that have less than 3 words\n",
    "new_df = new_df[new_df['text'].str.count(' ') >= 2]\n",
    "\n",
    "# remove rows that have links\n",
    "new_df = new_df[~new_df['text'].str.contains('http')]\n",
    "\n",
    "# remove rows that have mentions\n",
    "new_df = new_df[~new_df['text'].str.contains('@')]\n",
    "\n",
    "# remove duplicate rows\n",
    "new_df = new_df.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emojis from comment\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# remove punctuation from comment\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# remove numbers from comment\n",
    "def remove_numbers(text):\n",
    "    return text.translate(str.maketrans('', '', string.digits))\n",
    "\n",
    "# remove arabic ponctuation from comment\n",
    "def remove_arabic_punctuation(text):\n",
    "    arabic_punctuation = 'ØŸØŒØ›Û”Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'\n",
    "    return text.translate(str.maketrans('', '', arabic_punctuation))\n",
    "\n",
    "# remove english characters from comment\n",
    "def remove_english_characters(text):\n",
    "    english_characters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    return text.translate(str.maketrans('', '', english_characters))\n",
    "\n",
    "def remove_repetition(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text) # Replace with only one (remove repetitions)  \n",
    "\n",
    "def clean_text(text):\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_arabic_punctuation(text)\n",
    "    text = remove_english_characters(text)\n",
    "    text = remove_repetition(text)\n",
    "    return text\n",
    "\n",
    "new_df = df['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"data/train_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
